{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전준비\n",
    "### 1. 랭체인 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU openai langchain langchain-naver "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 공통 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import uuid\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import http\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. API 키 발급 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CLOVASTUDIO_API_KEY\"] = getpass.getpass(\"CLOVA Studio API Key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문서 전처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. PDF 문서에서 텍스트와 이미지 추출하기 (Load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def confirm(t):\n",
    "    a = [] \n",
    "    a.append(t)\n",
    "    a.append(t+1)\n",
    "    return a\n",
    "a = []\n",
    "a.extend(confirm(1))\n",
    "a.extend(confirm(2))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def extract_documents_from_pdf(pdf_path: str, output_dir: str = \"data/extracted_images_문서\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    merged_text_path = os.path.join(output_dir, \"merged_text.txt\")\n",
    "    merged_text = \"\"\n",
    "\n",
    "    doc = fitz.open(pdf_path)\n",
    "    documents = []\n",
    "\n",
    "    for i, page in enumerate(doc):\n",
    "        page_number = i + 1\n",
    "        page_text = page.get_text(\"text\").strip()\n",
    "        images_info = []\n",
    "\n",
    "        # 이미지 추출\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            image_filename = f\"page_{page_number}_img_{img_index+1}.{image_ext}\"\n",
    "            image_path = os.path.join(output_dir, image_filename)\n",
    "\n",
    "            with open(image_path, \"wb\") as img_file:\n",
    "                img_file.write(image_bytes)\n",
    "\n",
    "            images_info.append(image_path)\n",
    "\n",
    "        # LangChain Document로 변환\n",
    "        documents.append(Document(\n",
    "            page_content=page_text,\n",
    "            metadata={\n",
    "                \"source\": os.path.basename(pdf_path),\n",
    "                \"page\": page_number,\n",
    "                \"images\": \", \".join(images_info)\n",
    "            }\n",
    "        ))\n",
    "\n",
    "        # 병합 텍스트 저장용\n",
    "        merged_text += f\"\\n\\n--- Page {page_number} ---\\n\\n{page_text}\"\n",
    "\n",
    "    # 전체 텍스트 저장\n",
    "    with open(merged_text_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(merged_text)\n",
    "\n",
    "    return documents, merged_text_path\n",
    "\n",
    "pdf_path = \"data/modeltuning.pdf\"\n",
    "docs, merged_path = extract_documents_from_pdf(pdf_path)\n",
    "\n",
    "print(f\"추출된 문서 페이지 수: {len(docs)}\")\n",
    "print(f\"병합된 텍스트 경로: {merged_path}\")\n",
    "print(docs[0])  # 하나 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "def check_and_resize_image_to_outdir(\n",
    "    path: Path,\n",
    "    outdir: Path,\n",
    "    allowed_formats=(\"PNG\", \"JPEG\", \"WEBP\", \"BMP\"),\n",
    "    max_bytes=20 * 1024 * 1024,\n",
    "    max_length=2240,\n",
    "    max_ratio=4.5,\n",
    "    save_format=\"PNG\"\n",
    "):\n",
    "    try:\n",
    "        # 용량 초과 확인\n",
    "        if path.stat().st_size > max_bytes:\n",
    "            print(f\"[✘] 용량 초과: {path.name}\")\n",
    "            return\n",
    "\n",
    "        with Image.open(path) as image:\n",
    "            format = image.format.upper()\n",
    "            if format not in allowed_formats:\n",
    "                print(f\"[✘] 포맷 불가: {path.name} ({format})\")\n",
    "                return\n",
    "\n",
    "            w, h = image.size\n",
    "            ratio = max(w, h) / min(w, h)\n",
    "            needs_resize = max(w, h) > max_length or ratio > max_ratio\n",
    "\n",
    "            if not needs_resize:\n",
    "                # 조건 만족 → 그대로 복사\n",
    "                dest = outdir / path.name\n",
    "                shutil.copy(path, dest)\n",
    "                print(f\"[✓] 조건 만족 → 복사됨: {path.name}\")\n",
    "                return\n",
    "\n",
    "            # 리사이즈 크기 계산\n",
    "            if ratio > max_ratio:\n",
    "                if w > h:\n",
    "                    new_w = min(w, max_length)\n",
    "                    new_h = int(new_w / max_ratio)\n",
    "                else:\n",
    "                    new_h = min(h, max_length)\n",
    "                    new_w = int(new_h / max_ratio)\n",
    "            else:\n",
    "                if w >= h:\n",
    "                    new_w = min(w, max_length)\n",
    "                    new_h = int(h * (new_w / w))\n",
    "                else:\n",
    "                    new_h = min(h, max_length)\n",
    "                    new_w = int(w * (new_h / h))\n",
    "\n",
    "            resized = image.resize((new_w, new_h), Image.LANCZOS).convert(\"RGB\")\n",
    "            dest = outdir / path.name\n",
    "            resized.save(dest, format=save_format, optimize=True)\n",
    "            print(f\"[✔] 리사이즈됨 → 저장됨: {dest.name} ({new_w}x{new_h})\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[✘] 처리 실패: {path.name} → {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "input_dir = Path(\"data/extracted_images_문서\")\n",
    "output_dir = Path(\"data/filtered_images\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "valid_exts = [\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\"]\n",
    "image_files = [p for p in input_dir.glob(\"*\") if p.suffix.lower() in valid_exts]\n",
    "\n",
    "print(f\"총 {len(image_files)}개의 이미지 처리 시작\")\n",
    "\n",
    "for img_path in image_files:\n",
    "    check_and_resize_image_to_outdir(img_path, outdir=output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 클라우드에서 발급받은 키를 입력하세요\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = getpass.getpass(\"NCP Access Key: \")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = getpass.getpass(\"NCP Secret Key: \")\n",
    "\n",
    "# 기본 리전 설정\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"kr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ncloud Object Storage 에 이미지 저장 및 링크 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "from botocore.exceptions import ClientError\n",
    "import mimetypes\n",
    "\n",
    "# 설정\n",
    "BUCKET_NAME = \"multi-rag-techseminar\"\n",
    "LOCAL_FOLDER = \"data/filtered_images\"\n",
    "ENDPOINT_URL = \"https://kr.ncloudstorage.com\"\n",
    "REGION = os.environ[\"AWS_DEFAULT_REGION\"]\n",
    "\n",
    "ACCESS_KEY = os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "SECRET_KEY = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "\n",
    "# boto3 클라이언트 초기화\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=ACCESS_KEY,\n",
    "    aws_secret_access_key=SECRET_KEY,\n",
    "    endpoint_url=ENDPOINT_URL,\n",
    "    region_name=REGION,\n",
    "    config=Config(signature_version=\"s3v4\")\n",
    ")\n",
    "\n",
    "# 1. 버킷 생성\n",
    "try:\n",
    "    s3.head_bucket(Bucket=BUCKET_NAME)\n",
    "    print(f\"이미 존재하는 버킷입니다: {BUCKET_NAME}\")\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == '404':\n",
    "        print(f\"버킷이 존재하지 않아 생성합니다: {BUCKET_NAME}\")\n",
    "        s3.create_bucket(Bucket=BUCKET_NAME)\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# 2. 이미지 수집\n",
    "IMAGE_EXTENSIONS = (\"*.jpeg\", \"*.jpg\", \"*.png\", \"*.bmp\", \"*.webp\")\n",
    "image_files = []\n",
    "\n",
    "for ext in IMAGE_EXTENSIONS:\n",
    "    image_files.extend(glob(os.path.join(LOCAL_FOLDER, ext)))\n",
    "\n",
    "print(f\"총 {len(image_files)}개 이미지 파일을 찾았습니다.\")\n",
    "\n",
    "# 3. 이미지 업로드 및 URL 저장\n",
    "url_list = [] # 결과 저장할 리스트\n",
    "\n",
    "for file_path in image_files:\n",
    "    file_name = os.path.basename(file_path)\n",
    "\n",
    "    try:\n",
    "        # 업로드\n",
    "        s3.upload_file(file_path, BUCKET_NAME, file_name)\n",
    "\n",
    "        # MIME 타입 추정\n",
    "        mime_type, _ = mimetypes.guess_type(file_name)\n",
    "        if not mime_type:\n",
    "            mime_type = \"application/octet-stream\"\n",
    "\n",
    "        # Signed URL 생성\n",
    "        signed_url = s3.generate_presigned_url(\n",
    "            \"get_object\",\n",
    "            Params={\n",
    "                \"Bucket\": BUCKET_NAME,\n",
    "                \"Key\": file_name,\n",
    "                \"ResponseContentDisposition\": \"inline\",\n",
    "                \"ResponseContentType\": mime_type\n",
    "            },\n",
    "            ExpiresIn=3600\n",
    "        )\n",
    "\n",
    "        print(f\"URL: {signed_url}\")\n",
    "        url_list.append(signed_url)\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(f\"업로드 실패: {e}\")\n",
    "\n",
    "\n",
    "print(\"모든 이미지 업로드 및 링크 생성 완료!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_naver import ChatClovaX\n",
    "\n",
    "chat_llm = ChatClovaX(\n",
    "    model=\"HCX-005\"\n",
    ")\n",
    "\n",
    "# 이미지 URL\n",
    "image_url = url_list[-1]\n",
    "\n",
    "# System, User prompt 구성\n",
    "system_message = SystemMessage(\n",
    "    content=(\n",
    "        \"당신은 문서 내 다양한 형태의 이미지를 분석하여, 검색 기반 질문응답 시스템(RAG)에 활용 가능한 텍스트 설명을 생성하는 AI입니다.\"\n",
    "        \"이미지는 인포그래픽, 표, 그래프, 코드 캡처, 다이어그램, 화면 구성 등 다양한 유형일 수 있으며, 다음 기준에 따라 요약을 작성하세요.\"\n",
    "        \"- 이미지의 주제와 목적을 명확하게 파악하고 자연어로 요약합니다.\"\n",
    "        \"- 이미지가 전달하는 구조나 흐름이 있다면 순차적으로 설명합니다. (예: 단계, 관계, 비교 등)\"\n",
    "        \"- 표, 그래프, 수치 정보는 전체 흐름과 특징적인 차이만 요약하고, 수치 나열은 피합니다.\"\n",
    "        \"- 코드 캡처인 경우 기능과 역할 중심으로 요약하며, 함수/변수/모듈명 등 핵심 정보만 포함합니다.\"\n",
    "        \"- 시각적 요소(색상, 도형, 배치 등)는 정보 전달에 필요할 경우에만 간단히 설명합니다.\"\n",
    "        \"- OCR로 추출된 텍스트가 있다면 핵심 내용 위주로 정리하여 포함합니다.\"\n",
    "        \"- 설명은 검색 가능한 핵심 키워드를 포함하고, 감상이나 해석 없이 사실 중심 문장으로 구성해야 합니다.\"\n",
    "        \"- 최종 출력은 3~5문장 이내의 단일 문단으로 구성되며, RAG 시스템의 컨텍스트로 직접 활용 가능해야 합니다.\"\n",
    "    )\n",
    ")\n",
    "human_message = HumanMessage(content=[\n",
    "        {\"type\": \"text\", \"text\": \"이 이미지는 문서 내 시각 자료입니다. 핵심 정보를 요약해 주세요.\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "    ])\n",
    "\n",
    "# 메시지 구성\n",
    "messages = [\n",
    "    system_message,\n",
    "    human_message\n",
    "    ]\n",
    "\n",
    "# 파라미터 설정\n",
    "config={\n",
    "        \"generation_config\": {\n",
    "            \"temperature\": 0.25,\n",
    "            \"repetition_penalty\": 1.1\n",
    "        }\n",
    "    }\n",
    "\n",
    "# 모델 호출\n",
    "response = chat_llm.invoke(messages,config)\n",
    "print(\"[CLOVA 응답]\\n\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 저장할 딕셔너리\n",
    "image_summary_results = []\n",
    "\n",
    "# URL 반복 → 프롬프트 생성 → 모델 호출 → 딕셔너리 저장\n",
    "for url in url_list:\n",
    "    file_name = os.path.basename(url)\n",
    "    clean_filename = file_name.split(\"?\")[0]\n",
    "    try:\n",
    "        # URL만 바꿔서 human_message 재생성\n",
    "        human_message.content[1][\"image_url\"][\"url\"] = url\n",
    "        messages = [system_message, human_message]\n",
    "        response = chat_llm.invoke(messages,config)\n",
    "\n",
    "        # 결과 딕셔너리에 저장\n",
    "        image_summary_results.append({clean_filename: response.content})\n",
    "        print(f\"[✔] 저장 완료: {url}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[✘] 실패: {url} → {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지를 document 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_docs = []\n",
    "for item in image_summary_results:\n",
    "    # 각 딕셔너리에서 파일명과 요약 텍스트 추출\n",
    "    file_name = list(item.keys())[0]\n",
    "    summary = item[file_name]\n",
    "\n",
    "    # 정규식으로 페이지 번호 추출\n",
    "    match = re.search(r'page_(\\d+)_img_\\d+\\.\\w+', file_name)\n",
    "    page_number = int(match.group(1)) if match else None\n",
    "\n",
    "    # LangChain Document 생성\n",
    "    image_docs.append(Document(\n",
    "        page_content=summary,\n",
    "        metadata={\n",
    "            \"source\": \"modeltuning.pdf\",\n",
    "            \"page\": page_number,\n",
    "            \"images\": file_name\n",
    "        }\n",
    "    ))\n",
    "\n",
    "print(f\"총 {len(image_docs)}개의 Document 생성 완료\")\n",
    "print(image_docs[0].page_content)\n",
    "print(image_docs[0].metadata)  # 하나 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "class CompletionExecutor:\n",
    "    def __init__(self, host, api_key, request_id):\n",
    "        self._host = host\n",
    "        self._api_key = api_key\n",
    "        self._request_id = request_id\n",
    "\n",
    "    def _send_request(self, completion_request):\n",
    "        headers = {\n",
    "            'Content-Type': 'application/json; charset=utf-8',\n",
    "            'Authorization': self._api_key,\n",
    "            'X-NCP-CLOVASTUDIO-REQUEST-ID': self._request_id\n",
    "        }\n",
    "\n",
    "        conn = http.client.HTTPSConnection(self._host)\n",
    "        conn.request('POST', '/testapp/v1/api-tools/segmentation', json.dumps(completion_request), headers)\n",
    "        response = conn.getresponse()\n",
    "        result = json.loads(response.read().decode(encoding='utf-8'))\n",
    "        conn.close()\n",
    "        return result\n",
    "\n",
    "    def execute(self, completion_request):\n",
    "        res = self._send_request(completion_request)\n",
    "        if res['status']['code'] == '20000':\n",
    "            return res['result']['topicSeg']\n",
    "        else:\n",
    "            print(\"[CLOVA 응답 오류]\", res['status'])\n",
    "            return 'Error'\n",
    "        \n",
    "file_path = \"data/extracted_images_문서/merged_text.txt\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text_content = f.read()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    completion_executor = CompletionExecutor(\n",
    "        host='clovastudio.stream.ntruss.com',\n",
    "        api_key=\"Bearer \"+os.environ[\"CLOVASTUDIO_API_KEY\"], # 여기 키 형식이 Bearer이 붙네요 \n",
    "        request_id=str(uuid.uuid4())\n",
    "    )\n",
    "\n",
    "    chunked_docs = []\n",
    "\n",
    "    for doc in docs:  # docs는 페이지별로 추출한 Document 리스트\n",
    "        segments = completion_executor.execute(\n",
    "            # 이전 블로그 참고해 파라미터 설정\n",
    "            {\"postProcessMaxSize\": 100,   # 후처리 시 하나의 문단이 가질 수 있는 최대 글자 수 (예: 1000자 이하로 잘라줌)\n",
    "            \"alpha\": -100,                # 문단 나누기 민감도 조절 파라미터 (기본: 0.0 / -100으로 두면 자동 조정) - 값이 클수록 더 잘게 나뉘고, 작을수록 덜 나뉨\n",
    "            \"segCnt\": -1,                 # 원하는 문단 개수 설정 (-1이면 자동 분할, 1 이상의 정수 입력 시 해당 개수로 고정)\n",
    "            \"postProcessMinSize\": -1,     # 후처리 시 하나의 문단이 가져야 할 최소 글자 수 (예: 300자 이상 유지)\n",
    "            \"text\": doc.page_content,     # 실제 분할할 원본 텍스트\n",
    "            \"postProcess\": True}          # 후처리 여부 설정 (True: 문단 길이 균일화 / False: 모델 출력 그대로 사용)\n",
    "        )\n",
    "\n",
    "    for seg in segments:\n",
    "        chunked_docs.append(Document(\n",
    "            page_content=' '.join(seg),\n",
    "            metadata=doc.metadata\n",
    "        ))    \n",
    "\n",
    "    print(chunked_docs)\n",
    "    print(\"chunk 개수 :\",len(chunked_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_docs를 chunked_docs에 추가 (원본은 그대로 유지)\n",
    "combined_docs = chunked_docs + image_docs\n",
    "\n",
    "print(f\"전체 chunk 개수: {len(combined_docs)}\")\n",
    "print(combined_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 청크 출력\n",
    "print(\"\\n샘플 청크 (처음 3개):\")\n",
    "for i, chunk in enumerate(combined_docs[:3], 0):\n",
    "    print(f\"\\n청크 {i+1}:\")\n",
    "    print(f\"내용: {chunk.page_content}\")\n",
    "    print(f\"metadata: {chunk.metadata}\")\n",
    "    print(f\"길이: {len(chunk.page_content)}자\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_naver import ClovaXEmbeddings\n",
    " \n",
    "clovax_embeddings = ClovaXEmbeddings(model='bge-m3') # 임베딩 모델을 설정\n",
    "\n",
    "text = \"임베딩 사용 예제입니다~\"\n",
    " \n",
    "clovax_embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chroma 다운받기\n",
    "%pip install -qU langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "# 임베딩 모델 정의\n",
    "clovax_embeddings = ClovaXEmbeddings(model='bge-m3')\n",
    "\n",
    "# 로컬 클라이언트 생성\n",
    "client = chromadb.PersistentClient(path=\"./Chroma_langchain_db123\")\n",
    "\n",
    "# 컬렉션 준비 (이름 중복 주의!)\n",
    "collection_name = \"clovastudiodatas_docs\"\n",
    "client.get_or_create_collection(\n",
    "    name=collection_name,\n",
    "    metadata={\"hnsw:space\": \"cosine\"}\n",
    ")\n",
    "\n",
    "# 벡터스토어 객체 생성\n",
    "vectorstore_Chroma = Chroma(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embedding_function=clovax_embeddings\n",
    ")\n",
    "\n",
    "# 문서 추가: 최신 방식은 vectorstore.add_documents 사용\n",
    "print(\"Adding documents to Chroma vectorstore...\")\n",
    "for doc in combined_docs:\n",
    "    try:\n",
    "        vectorstore_Chroma.add_documents([doc])\n",
    "        time.sleep(1.1) \n",
    "    except Exception as e:\n",
    "        print(f\"[✘] 실패: {doc.metadata} → {e}\")\n",
    "\n",
    "print(\"All documents have been added to the vectorstore.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FAISS 다운로드\n",
    "%pip install -qU langchain-community faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "# 임베딩 모델 정의\n",
    "clovax_embeddings = ClovaXEmbeddings(model='bge-m3')\n",
    "\n",
    "# FAISS 인덱스 생성 (1024는 bge-m3 차원 수에 맞춰야 함)\n",
    "index = faiss.IndexFlatIP(1024)  # 내적 기반 검색\n",
    "\n",
    "# FAISS 벡터스토어 생성\n",
    "vectorstore_FAISS = FAISS(\n",
    "    embedding_function=clovax_embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")\n",
    "\n",
    "# 문서 일괄 추가 (자동 임베딩 처리)\n",
    "print(\"Adding documents to FAISS vectorstore...\")\n",
    "for doc in combined_docs:\n",
    "    try:\n",
    "        vectorstore_FAISS.add_documents([doc])\n",
    "        time.sleep(1.1) \n",
    "    except Exception as e:\n",
    "        print(f\"[✘] 실패: {doc.metadata} → {e}\")\n",
    "print(\"All documents have been added to FAISS vectorstore.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 질의하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 질문하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# System 및 User 메시지를 나눠 구성\n",
    "system_template = (\n",
    "    \"당신은 질문-답변(Question-Answering)을 수행하는 친절한 AI 어시스턴트입니다. 당신의 임무는 원래 가지고있는 지식은 모두 배제하고, 주어진 문맥(context) 에서 주어진 질문(question) 에 답하는 것입니다.\"\n",
    "    \"만약, 주어진 문맥(context) 에서 답을 찾을 수 없다면, 답을 모른다면 `주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다` 라고 답하세요.\"\n",
    ")\n",
    "user_template = (\n",
    "    \"다음은 검색된 문서 내용입니다:\\n\\n{context}\\n\\n\"\n",
    "    \"위 정보를 바탕으로 다음 질문에 답해주세요:\\n{question}\"\n",
    ")\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(user_template),\n",
    "])\n",
    "\n",
    "# 원하는 vectorstore 선택해서 사용\n",
    "retriever = vectorstore_Chroma.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": 0.1, \"k\": 3}\n",
    "    )\n",
    "# retriever = vectorstore_FAISS.as_retriever(\n",
    "#     search_type=\"similarity_score_threshold\",\n",
    "#     search_kwargs={\"score_threshold\": 0.1, \"k\": 3}\n",
    "# )\n",
    "\n",
    "# Retrieval QA 체인 구성\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat_llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# 실행\n",
    "question = \"데이터셋 규모가 커질수록 2대륙의 오류 발생 확률은 어떻게 돼?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "\n",
    "print(\"질문:\", question)\n",
    "print(\"응답:\", result[\"result\"])  # 모델의 실제 응답\n",
    "for i, doc in enumerate(result[\"source_documents\"]): # 답변시 참고 한 문서\n",
    "    print(f\"\\n[출처 문서 {i+1}]\\n내용: {doc.page_content}\\n메타데이터: {doc.metadata}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

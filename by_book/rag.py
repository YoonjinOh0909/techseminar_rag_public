import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
import retriever
import os
from dotenv import load_dotenv

load_dotenv()
HF_API_KEY = os.getenv("HF_API_KEY")
LANGSMITH_API_KEY = os.getenv("LANGSMITH_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatOpenAI(
    model="openai/gpt-oss-120b",  # Hugging Face Routerì˜ ëª¨ë¸
    openai_api_key=HF_API_KEY,
    openai_api_base="https://router.huggingface.co/v1"  # base_url ëŒ€ì‹  ì‚¬ìš©
)

# ì‚¬ìš©ìì˜ ë©”ì‹œì§€ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ í•¨ìˆ˜
def get_ai_response(messages, docs):    
    response = retriever.document_chain.stream({
        "messages": messages,
        "context": docs
    })

    for chunk in response:
        yield chunk

# Streamlit ì•±
st.title("ğŸ’¬ GPT-4o Langchain Chat")

# ìŠ¤íŠ¸ë¦¼ë¦¿ session_stateì— ë©”ì‹œì§€ ì €ì¥
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        SystemMessage("ë‹¹ì‹ ì€ ì‚¬ìš©ìë¥¼ ìœ„í•œ ì „ë¬¸ ëŒ€ì¶œ ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤. "
            "ë‹¹ì‹ ì˜ ì—­í• ì€ ì¼ë°˜ ì‹ ìš©ëŒ€ì¶œ ë° ë¶€ë™ì‚° ê´€ë ¨ ëŒ€ì¶œì— ëŒ€í•´ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ìƒë‹´ì„ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. "
            "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë°˜ë“œì‹œ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰ëœ retrieved context(RAG) ê¸°ë°˜ìœ¼ë¡œë§Œ ë‹µë³€í•´ì•¼ í•˜ë©°, "
            "retrieved contextì— ì—†ëŠ” ì •ë³´ë¥¼ ì¶”ë¡ í•˜ê±°ë‚˜ ì„ì˜ë¡œ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì‹­ì‹œì˜¤. "
            "ë‹¤ìŒ ê·œì¹™ì„ ë°˜ë“œì‹œ ë”°ë¥´ì‹­ì‹œì˜¤:\n"
            "1. ë‹µë³€ì€ retrieved contextì— í¬í•¨ëœ ì •ë³´ì— ê¸°ë°˜í•˜ì—¬ ì‘ì„±í•©ë‹ˆë‹¤.\n"
            "2. retrieved contextì— ê´€ë ¨ ì •ë³´ê°€ ì—†ì„ ê²½ìš°, \"í•´ë‹¹ ë‚´ìš©ì€ ë¬¸ì„œì— ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì „ë¬¸ ìƒë‹´ì‚¬ì—ê²Œ ì—°ê²°í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\" ë¼ê³  ë‹µë³€í•©ë‹ˆë‹¤.\n"
            "3. ë‹µë³€ ì‘ì„± ì‹œ ì¼ë°˜ì ì¸ ìƒí™©ë¿ë§Œ ì•„ë‹ˆë¼ ë°œìƒí•  ìˆ˜ ìˆëŠ” íŠ¹ìˆ˜ ìƒí™©ë„ í•¨ê»˜ ê³ ë ¤í•˜ì—¬ ì„¤ëª…í•©ë‹ˆë‹¤.\n"
            "4. ë‹µë³€ì€ ë‹¤ìŒ Markdown í‘œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤:\n"
            "5. ë‹µë³€í•  ìˆ˜ ìˆëŠ” ì¢…ë¥˜ê°€ ë§ë‹¤ë©´ ìµœëŒ€ 5ê°œê¹Œì§€ ì„¤ëª…í•©ë‹ˆë‹¤.\n"
            "(ê°„ë‹¨ ìš”ì•½)\n"
            "(í‘œ)\n"
            "(ì§ˆë¬¸ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…)\n"
            "**ì¶œì²˜**\n"
            "- (ë¬¸ì„œëª…) (í˜ì´ì§€ ë²”ìœ„) â€œ(20ì ì´í•˜ ì¸ìš©ë¬¸)â€¦\"\n"
            "5. ë§ˆì§€ë§‰ ì¤„ì—ëŠ” ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í•µì‹¬ì´ ë˜ëŠ” í‚¤ì›Œë“œë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•©ë‹ˆë‹¤: "
            "í‚¤ì›Œë“œ : (keyword1, keyword2, ...)\n"
            "#Context: {context}"),  
        AIMessage("How can I help you?")
    ]

# ìŠ¤íŠ¸ë¦¼ë¦¿ í™”ë©´ì— ë©”ì‹œì§€ ì¶œë ¥
for msg in st.session_state.messages:
    if msg.content:
        if isinstance(msg, SystemMessage):
            st.chat_message("system").write(msg.content)
        elif isinstance(msg, AIMessage):
            st.chat_message("assistant").write(msg.content)
        elif isinstance(msg, HumanMessage):
            st.chat_message("user").write(msg.content)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input():
    st.chat_message("user").write(prompt) # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
    st.session_state.messages.append(HumanMessage(prompt)) # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥

    augmented_query = retriever.query_augmentation_chain.invoke({
        "messages": st.session_state["messages"],
        "query": prompt,
    })
    print("augmented_query\t", augmented_query)

    # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    print("ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰")
    docs = retriever.retriever.invoke(f"{prompt}\n{augmented_query}")

    for doc in docs:
        print('---------------')
        print(doc)   
    print("===============")

    with st.spinner(f"AIê°€ ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤... '{augmented_query}'"):
        response = get_ai_response(st.session_state["messages"], docs)
        result = st.chat_message("assistant").write_stream(response) # AI ë©”ì‹œì§€ ì¶œë ¥
    st.session_state["messages"].append(AIMessage(result)) # AI ë©”ì‹œì§€ ì €ì¥    